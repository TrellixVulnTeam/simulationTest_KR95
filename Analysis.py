import pyAgrum as gum
import copy as copy
from Experiment import Experiment
from BN import K2_BN
import csv
import pandas as pd
import math
import numpy as np

import csv
import pandas as pd


def disturb_cpts(experiment, disturb_type, params_list):
    file_name = "K2BN.net"
    K2_BN(experiment, "globalStates.csv", file_name)

    bn = gum.loadBN(file_name)
    noise_list = []

    if disturb_type == "normalNoise":
        '''
        The probabilities in the cpt are not the probabilities generated by K2,
        but they're distorted by a noise error (e)
            X'(X=1) = X(X=1) - e
            X'(X=0) = X(X=0) + e    (or vice versa)

        where e is drawn from a truncatec normal distribution with 
        M = 0, SD = 0.2 (tune parameters later) - the distribution cannot be o . For
        every variable we draw again from this normal distribution.

        This might represent the best case scenario for human estimations
        of probability - even if we cannot know the exact probability,
        we might be able to estimate them closely enough.

        However, it is very likely that our probability estimations
        do not work according to this standard-noise model. For instance,
        racial (or other societal) biases cannot be assumed to 
        be modelled with a "normal" divergence (the noise will be
        predisposed to go into "one direction", and not the other).

        However, first we need to see if BNs are robust against this 
        most simple noise-type of error.

        '''
        m, sd, type = params_list
        smallest_change = 1
        largest_change = 0
        nodes = bn.nodes()  # list of nodes to iterate over (names don't matter because noise is all the same
        for node in list(nodes):
            x = bn.cpt(node)
            name = x.var_names[-1]
            e = np.random.normal(loc=m, scale=sd)
            noise_list.append(e)
            # print(name, e)
            for i in bn.cpt(name).loopIn():
                if i.todict()[name] == 0:
                    bn.cpt(name).set(i, keep_in_range(bn.cpt(name).get(i) + e))
                elif i.todict()[name] == 1:
                    bn.cpt(name).set(i, keep_in_range(bn.cpt(name).get(i) - e))
            if abs(e) > largest_change:
                largest_change = abs(e)
            if abs(e) < smallest_change:
                smallest_change = abs(e)
        # print(largest_change, smallest_change)
        final_file_name = f"{disturb_type}BN{str(sd)}"
        gum.saveBN(bn, f"{final_file_name}.net")
        # print(f"saved bn as {file_name}")
        return [final_file_name, [largest_change, smallest_change]]

    if disturb_type == "rounded":
        ''' we want to round the BN
        to some degree of decimals,
        since humans are not really accurate at 0.0001
        estimations.
        So then we want to get to 0.1, or 0.01 level rounding  (params_list)
        in the network, to see what happens then.
        '''
        [decimal_place, rounded_name] = params_list
        nodes = bn.nodes()  # list of nodes to iterate over (names don't matter because noise is all the same
        for node in list(nodes):
            x = bn.cpt(node)
            name = x.var_names[-1]
            for i in bn.cpt(name).loopIn():
                bn.cpt(name).set(i, round(bn.cpt(name).get(i), decimal_place))
        final_file_name = f"{disturb_type}BN{str(decimal_place)}"
        gum.saveBN(bn, f"{final_file_name}.net")
        return [final_file_name, "empty"]

    if disturb_type == "arbitraryRounded":
        ''' we want to round the BN
        to some degree (round to quartile, octile, thirds, 2nds, hwatever,
        since we like round numbers

        '''
        [step, rounded_name] = params_list
        nodes = bn.nodes()  # list of nodes to iterate over (names don't matter because noise is all the same
        for node in list(nodes):
            x = bn.cpt(node)
            name = x.var_names[-1]
            for i in bn.cpt(name).loopIn():
                val = bn.cpt(name).get(i)
                val = val
                y = math.floor((val / step) + 0.5) * step
                bn.cpt(name).set(i, y)
        final_file_name = f"{disturb_type}BN{str(step)}"
        gum.saveBN(bn, f"{final_file_name}.net")
        return [final_file_name, "empty"]


def determine_winning_hypothesis(false_val, true_val):
    x = ""
    if false_val > true_val:
        x = "H0"
    elif false_val < true_val:
        x = "H1"
    else:
        x = "0"
    return x

def find_posterior_based_on_evidence():
    pass

def determine_posterior_direction_or_precision(file_name, direction):  # type is 'direction' or 'precision
    if file_name != "BayesNets/K2BN.net":
        bn = gum.loadBN(f"{file_name}.net")
    else:
        bn = gum.loadBN(file_name)
    direction_dict = {}
    ie = gum.LazyPropagation(bn)
    event_list = experiment.reporters.relevant_events
    e_dict = {}
    for node in list(bn.nodes()):
        x = bn.cpt(node)
        name = x.var_names[-1]
        if name[0] != 'E':  # we do not care about evidence nodes
            if direction == "weak":
                e_dict[name] = determine_winning_hypothesis(ie.posterior(node)[0], ie.posterior(node)[1]) # compare the posteriors (false, true) for node "name"
            elif direction == "strong":  # we just want to know the posterior for truth of a node
                e_dict[name] = round(ie.posterior(node)[1], 2)

    direction_dict[("no_evidence", 0)] = e_dict

    evidence_list = []
    for ev in event_list:
        if ev[0] == 'E':  # evidence node TODO make a seperate class
            evidence_list.append(ev)
    for evidence in evidence_list:
        e_dict = {}
        if evidence != "E_private":
            val = 1
        else:
            val = 0
        ie.addEvidence(evidence, val)
        for node in list(bn.nodes()):
            x = bn.cpt(node)
            name = x.var_names[-1]
            if name[0] != 'E':  # we do not care about evidence nodes
                try:
                    if direction == "weak":
                        e_dict[name] = determine_winning_hypothesis(ie.posterior(node)[0], ie.posterior(node)[1])
                    else:
                        e_dict[name] = round(ie.posterior(node)[1], 2)
                except:
                    e_dict[name] = "N/A"
        direction_dict[(evidence, val)] = e_dict
    return direction_dict

def keep_in_range(x):
    ''' numbers in a ctp cannot be > 1 or < 0'''
    if x > 1:
        return 1
    if x < 0:
        return 0
    return x

def make_table_headings_based_on_events(relevant_events):
    str_tabular_formatting = "\\begin{tabular}{l"
    for i in range(0, len(relevant_events)):
        str_tabular_formatting = str_tabular_formatting + "|cc"
    str_tabular_formatting = str_tabular_formatting + "}"

    str_head = "\\multirow{2}{*}{Evidence} "
    for e in relevant_events:
        l_key = e.replace("_", " ")
        str_head = str_head + "& \\multicolumn{2}{c}{" + l_key + "}"
    str_head = str_head + "\\\\"

    for e in relevant_events:
        str_head = str_head + "& {K2} & {Dev}"
    str_head = str_head + "\\\\"
    return str_tabular_formatting, str_head



def get_outcomes_in_table(d1, d_noise, latex_file_name, params, direction, noise, relevant_events):  # compare two direction dictionaries
    tab_f, head_f = make_table_headings_based_on_events(relevant_events)
    if len(relevant_events) > 3:
        outcomes = "outcomes"
    else:
        outcomes = "hypotheses"

    with open(latex_file_name, 'w') as file:
        file.write("\\begin{table}")
        file.write(tab_f)
        file.write("\\toprule")
        file.write(head_f)
        file.write("\\midrule\n")

        for e in d1.keys():
            l_key = e[0].replace("_", " ")
            file.write(str(l_key) + ", " + str(e[1]) + " & ")
            for x in relevant_events:
                if direction == "weak":
                    if not noise:   # if not noise
                        d2 = d_noise
                        if d1[e][x] == d2[e][x]:
                            file.write(str(d1[e][x]) + "&" + str(d2[e][x]))
                        else:
                            file.write(
                                "\\cellcolor{Bittersweet}" + str(d1[e][x]) + "&" + "\\cellcolor{Bittersweet}" + str(
                                    d2[e][x]))
                    else:   #if noise
                        count = 0
                        for d2 in d_noise:
                            if d1[e][x] == d2[e][x]:
                                count += 1
                        if (count / len(d_noise)) < 0.95:
                            file.write("\\cellcolor{Bittersweet}" + str(d1[e][x]) + "&" + "\\cellcolor{Bittersweet}" + str(
                                round(100 * (count / len(d_noise)), 0)))
                        else:
                            file.write(str(d1[e][x]) + "&" + str(round(100 * (count / len(d_noise)), 0)))
                if direction == "strong":
                    if not noise:   # something number of nodes
                        d2 = d_noise
                        if type(d2[e][x]) == float and abs(d1[e][x] - d2[e][x]) < 0.05:
                            file.write(str(d1[e][x]) + "&" + str(d2[e][x]))
                        else:
                            file.write(
                                "\\cellcolor{Bittersweet}" + str(d1[e][x]) + "&" + "\\cellcolor{Bittersweet}" + str(
                                    d2[e][x]))
                    else: # noise randomness precisison
                        count = 0
                        for d2 in d_noise:
                            if type(d2[e][x]) == float and d2[e][x] != "N/A":
                                count += d2[e][x]
                            else:
                                count += 0.5
                        if abs(d1[e][x] - (count / len(d_noise))) > 0.05:
                            file.write("\\cellcolor{Bittersweet}" + str(d1[e][x]) + "&" + "\\cellcolor{Bittersweet}" + str(
                                round((count / len(d_noise)), 0)))
                        else:
                            t = round((count / len(d_noise)), 0)
                            file.write(str(d1[e][x]) + "&" + str(t))

                if x != relevant_events[-1]:
                    file.write("&")
            file.write("\\\\")

        file.write("\\bottomrule")
        file.write("\\end{tabular}")
        file.write("\\caption{Effect of disturbance of " + str(params) + " on " + str(direction) + " view of " + str(outcomes) + ".}")
        file.write("\\end{table}")




def experiment_general_shape(type_exp, param_list, general_latex_file):
    d_2 = []
    noise = False
    relevant_files = []
    relevant_nodes_out = ["successful_stolen", "lost_object"]
    relevant_nodes_hyp = ["curtains", "raining", "know_object", "target_object", "motive", "compromise_house", "flees_startled"]
    for params in param_list:
        [disturbed_BN_file_name, empty] = disturb_cpts(experiment, type_exp, params)
        for direc in ["weak", "strong"]:
            d_1 = determine_posterior_direction_or_precision("BayesNets/K2BN.net", direc)
            if type_exp == "normalNoise":
                for i in range(0, 200):
                    noise = True
                    d_i = determine_posterior_direction_or_precision(disturbed_BN_file_name, direc)
                    d_2.append(d_i)
            else:
                [disturbed_BN_file_name, empty] = disturb_cpts(experiment, type_exp, params)
                d_2 = determine_posterior_direction_or_precision(disturbed_BN_file_name, direc)

            outcome_table = f'texTables/outcome/{direc}{disturbed_BN_file_name}.tex'
            hyp_table = f'texTables/hyps/{direc}{disturbed_BN_file_name}.tex'


            get_outcomes_in_table(d_1, d_2, outcome_table, params, direc, noise, relevant_nodes_out)
            get_outcomes_in_table(d_1, d_2, hyp_table, params, direc, noise, relevant_nodes_hyp)


            relevant_files.append(outcome_table)
            relevant_files.append(hyp_table)

    # output of experiment
    with open(general_latex_file, 'w') as file:
        for f in relevant_files:
            file.write("\\input{../simulationTest/" + f + "}\n")


experiment = Experiment()
K2_BN(experiment, "globalStates.csv", "BayesNets/K2BN.net")

param_no = [[0, 0.001, "Normal (M, sd)"], [0, 0.01, "Normal (M, sd)"], [0, 0.1, "Normal (M, sd)"],
                   [0, 0.2, "Normal (M, sd)"], [0, 0.3, "Normal (M, sd)"], [0, 0.5, "Normal (M, sd)"]]

param_ro = [[5, 'decimal places'], [4, 'decimal places'], [3, 'decimal places'],
                   [2, 'decimal places'], [1, 'decimal places'], [0, 'decimal places']]

param_ar = [[0.05, 'arbit'], [0.1, 'arbit'], [0.125, 'arbit'],
                   [0.2, 'arbit'], [0.25, 'arbit'],[0.33, 'arbit'],
                   [0.5, 'arbit']]

gen_file = '_collected_tables.tex'
for (exp, params) in [("rounded", param_ro), ("arbitraryRounded", param_ar), ("normalNoise", param_no)]:
    experiment_general_shape(exp, params, f"texTables/{exp}{gen_file}")
    print(f"done with experiment {exp}")
