import pyAgrum as gum
import copy as copy
from Experiment import Experiment
from BN import K2_BN
import csv
import pandas as pd
import math
import numpy as np

import csv
import pandas as pd


def disturb_cpts(experiment, disturb_type, params_list):
    file_name = "K2BN.net"
    K2_BN(experiment, "globalStates.csv", file_name)

    bn = gum.loadBN(file_name)
    noise_list = []

    if disturb_type == "normalNoise":
        '''
        The probabilities in the cpt are not the probabilities generated by K2,
        but they're distorted by a noise error (e)
            X'(X=1) = X(X=1) - e
            X'(X=0) = X(X=0) + e    (or vice versa)

        where e is drawn from a truncatec normal distribution with 
        M = 0, SD = 0.2 (tune parameters later) - the distribution cannot be o . For
        every variable we draw again from this normal distribution.

        This might represent the best case scenario for human estimations
        of probability - even if we cannot know the exact probability,
        we might be able to estimate them closely enough.

        However, it is very likely that our probability estimations
        do not work according to this standard-noise model. For instance,
        racial (or other societal) biases cannot be assumed to 
        be modelled with a "normal" divergence (the noise will be
        predisposed to go into "one direction", and not the other).

        However, first we need to see if BNs are robust against this 
        most simple noise-type of error.

        '''
        m, sd, type = params_list
        smallest_change = 1
        largest_change = 0
        nodes = bn.nodes()  # list of nodes to iterate over (names don't matter because noise is all the same
        for node in list(nodes):
            x = bn.cpt(node)
            name = x.var_names[-1]
            e = np.random.normal(loc=m, scale=sd)
            noise_list.append(e)
            # print(name, e)
            for i in bn.cpt(name).loopIn():
                if i.todict()[name] == 0:
                    bn.cpt(name).set(i, keep_in_range(bn.cpt(name).get(i) + e))
                elif i.todict()[name] == 1:
                    bn.cpt(name).set(i, keep_in_range(bn.cpt(name).get(i) - e))
            if abs(e) > largest_change:
                largest_change = abs(e)
            if abs(e) < smallest_change:
                smallest_change = abs(e)
        # print(largest_change, smallest_change)
        final_file_name = f"{disturb_type}BN{str(sd)}"
        gum.saveBN(bn, f"{final_file_name}.net")
        # print(f"saved bn as {file_name}")
        return [final_file_name, [largest_change, smallest_change]]

    if disturb_type == "rounded":
        ''' we want to round the BN
        to some degree of decimals,
        since humans are not really accurate at 0.0001
        estimations.
        So then we want to get to 0.1, or 0.01 level rounding  (params_list)
        in the network, to see what happens then.
        '''
        [decimal_place, rounded_name] = params_list
        nodes = bn.nodes()  # list of nodes to iterate over (names don't matter because noise is all the same
        for node in list(nodes):
            x = bn.cpt(node)
            name = x.var_names[-1]
            for i in bn.cpt(name).loopIn():
                bn.cpt(name).set(i, round(bn.cpt(name).get(i), decimal_place))
        final_file_name = f"{disturb_type}BN{str(decimal_place)}"
        gum.saveBN(bn, f"{final_file_name}.net")
        return [final_file_name, "empty"]

    if disturb_type == "arbitraryRounded":
        ''' we want to round the BN
        to some degree (round to quartile, octile, thirds, 2nds, hwatever,
        since we like round numbers

        '''
        [step, rounded_name] = params_list
        nodes = bn.nodes()  # list of nodes to iterate over (names don't matter because noise is all the same
        for node in list(nodes):
            x = bn.cpt(node)
            name = x.var_names[-1]
            for i in bn.cpt(name).loopIn():
                val = bn.cpt(name).get(i)
                val = val
                y = math.floor((val / step) + 0.5) * step
                bn.cpt(name).set(i, y)
        final_file_name = f"{disturb_type}BN{str(step)}"
        gum.saveBN(bn, f"{final_file_name}.net")
        return [final_file_name, "empty"]


def determine_winning_hypothesis(false_val, true_val):
    x = ""
    if false_val > true_val:
        x = "H0"
    elif false_val < true_val:
        x = "H1"
    else:
        x = "0"
    return x

def find_posterior_based_on_evidence():
    pass

def determine_posterior_direction_or_precision(file_name, direction):  # type is 'direction' or 'precision
    if file_name != "BayesNets/K2BN.net":
        bn = gum.loadBN(f"{file_name}.net")
    else:
        bn = gum.loadBN(file_name)
    direction_dict = {}
    ie = gum.LazyPropagation(bn)
    event_list = experiment.reporters.relevant_events
    e_dict = {}
    for node in list(bn.nodes()):
        x = bn.cpt(node)
        name = x.var_names[-1]
        if name[0] != 'E':  # we do not care about evidence nodes
            if direction == "direction":
                e_dict[name] = determine_winning_hypothesis(ie.posterior(node)[0], ie.posterior(node)[1]) # compare the posteriors (false, true) for node "name"
            elif direction == "precision":  # we just want to know the posterior for truth of a node
                e_dict[name] = round(ie.posterior(node)[1], 2)

    direction_dict[("no_evidence", 0)] = e_dict

    evidence_list = []
    for ev in event_list:
        if ev[0] == 'E':  # evidence node TODO make a seperate class
            evidence_list.append(ev)
    for evidence in evidence_list:
        e_dict = {}
        if evidence != "E_private":
            val = 1
        else:
            val = 0
        ie.addEvidence(evidence, val)
        for node in list(bn.nodes()):
            x = bn.cpt(node)
            name = x.var_names[-1]
            if name[0] != 'E':  # we do not care about evidence nodes
                try:
                    if direction == "direction":
                        e_dict[name] = determine_winning_hypothesis(ie.posterior(node)[0], ie.posterior(node)[1])
                    else:
                        e_dict[name] = round(ie.posterior(node)[1], 2)
                except:
                    e_dict[name] = "N/A"
        direction_dict[(evidence, val)] = e_dict
    return direction_dict


def comp(d1, d2, latex_file_name, params):  # compare two direction dictionaries
    with open(latex_file_name, 'w') as file:
        file.write("\\begin{table}")
        file.write("\\begin{tabular}{c|cc|cc}")
        file.write("\\toprule")
        file.write(
            "\\multirow{2}{*}{Evidence} & \\multicolumn{2}{c}{Successful Stolen} & \\multicolumn{2}{c}{Lost Object} \\\\"
            "& {K2} & {Dev} & {K2} & {Dev} \\\\")
        file.write("\\midrule\n")
        for e in d1.keys():
            l_key = e[0].replace("_", "\_")
            file.write(str(l_key) + ", " + str(e[1]) + " & ")
            for x in ["successful_stolen", "lost_object"]:
                if d1[e][x] == d2[e][x]:
                    file.write(str(d1[e][x]) + "&" + str(d2[e][x]))
                else:
                    file.write(
                        "\\cellcolor{Bittersweet}" + str(d1[e][x]) + "&" + "\\cellcolor{Bittersweet}" + str(d2[e][x]))
                if x == "successful_stolen":
                    file.write("&")
            file.write("\\\\")
        file.write("\\bottomrule")
        file.write("\\end{tabular}")
        file.write("\\caption{Different outcomes for disturbances in the cpts with params " + str(params) + "}")
        file.write("\\end{table}")


def comp_count(d1, d_noise, latex_file_name, params, direction):  # compare two direction dictionaries
    with open(latex_file_name, 'w') as file:
        file.write("\\begin{table}")
        file.write("\\begin{tabular}{c|cc|cc}")
        file.write("\\toprule")
        file.write(
            "\\multirow{2}{*}{Evidence} & \\multicolumn{2}{c}{Successful Stolen} & \\multicolumn{2}{c}{Lost Object} \\\\"
            "& {K2} & {Dev} & {K2} & {Dev} \\\\")
        file.write("\\midrule\n")

        for e in d1.keys():
            l_key = e[0].replace("_", "\_")
            file.write(str(l_key) + ", " + str(e[1]) + " & ")
            for x in ["successful_stolen", "lost_object"]:
                if direction == "direction":
                    #print(len(d_noise))
                    if len(d_noise) == 7:
                        d2 = d_noise
                        if d1[e][x] == d2[e][x]:
                            file.write(str(d1[e][x]) + "&" + str(d2[e][x]))
                        else:
                            file.write(
                                "\\cellcolor{Bittersweet}" + str(d1[e][x]) + "&" + "\\cellcolor{Bittersweet}" + str(
                                    d2[e][x]))
                    else:
                        count = 0
                        for d2 in d_noise:
                            #print(d2)
                            #print(d2[e][x])
                            if d1[e][x] == d2[e][x]:
                                count += 1
                        if (count / len(d_noise)) < 0.95:
                            file.write("\\cellcolor{Bittersweet}" + str(d1[e][x]) + "&" + "\\cellcolor{Bittersweet}" + str(
                                round(100 * (count / len(d_noise)), 0)))
                        else:
                            file.write(str(d1[e][x]) + "&" + str(round(100 * (count / len(d_noise)), 0)))
                if direction == "precision":
                    if len(d_noise) == 7:   #something number of nodes
                        d2 = d_noise
                        if d1[e][x] == d2[e][x]:
                            file.write(str(d1[e][x]) + "&" + str(d2[e][x]))
                        else:
                            file.write(
                                "\\cellcolor{Bittersweet}" + str(d1[e][x]) + "&" + "\\cellcolor{Bittersweet}" + str(
                                    d2[e][x]))
                    else:
                        count = 0
                        for d2 in d_noise:
                            if type(d2[e][x]) == float and d2[e][x] != "N/A":
                                #print(d2[e][x])
                                #print(count)
                                count += d2[e][x]
                            else:
                                count += 0.5
                        if abs(d1[e][x] - (count / len(d_noise))) > 0.05:
                            file.write("\\cellcolor{Bittersweet}" + str(d1[e][x]) + "&" + "\\cellcolor{Bittersweet}" + str(
                                round(100 * (count / len(d_noise)), 0)))
                        else:
                            t = round(100 * (count / len(d_noise)), 0)
                            file.write(str(d1[e][x]) + "&" + str(t))

                if x == "successful_stolen":
                    file.write("&")
            file.write("\\\\")

        file.write("\\bottomrule")
        file.write("\\end{tabular}")
        file.write("\\caption{Different outcomes for disturbances in the cpts with params " + str(params) + " " + str(direction) + "}")
        file.write("\\end{table}")


def keep_in_range(x):
    ''' numbers in a ctp cannot be > 1 or < 0'''
    if x > 1:
        return 1
    if x < 0:
        return 0
    return x


def get_hypothesis_posteriors_in_table(experiment, file_name, d1, d2, latex_file_name, params, flag, direction):
    if flag == "noise":
        d_noise = d2
    bnK2 = gum.loadBN(file_name)
    ie = gum.LazyPropagation(bnK2)
    event_list = experiment.reporters.relevant_events
    evidence_list = []
    for ev in event_list:
        if ev[0] == 'E':  # evidence node TODO make a seperate class
            evidence_list.append(ev)

    ie = gum.LazyPropagation(bnK2)
    with open(latex_file_name, 'w') as file:

        file.write("\\begin{table}")
        file.write("\\begin{tabular}{c|cc|cc|cc|cc|cc|cc|cc}")

        file.write("\\toprule")
        file.write("\\multirow{2}{*}{Evidence} & \\multicolumn{2}{c}{Raining} & "
                   "\\multicolumn{2}{c}{Curtains} & \\multicolumn{2}{c}{Know O}"
                   " & \\multicolumn{2}{c}{Target O} & \\multicolumn{2}{c}{Motive} &"
                   " \\multicolumn{2}{c}{CH} & \\multicolumn{2}{c}{Flees} &"
                   "  & {K2} & {Dev} & {K2} & {Dev} & {K2} & {Dev} & {K2} & {Dev} &"
                   " {K2} & {Dev} & {K2} & {Dev} & {K2} & {Dev}\\\\")
        file.write("\\midrule\n")
        for e in d1.keys():
            l_key = e[0].replace("_", "\_")
            file.write(str(l_key) + ", " + str(e[1]) + " & ")
            for x in ["curtains", "raining", "know_object",
                      "target_object", "motive", "compromise_house",
                      "flees_startled"]:
                if flag == "noise":
                    if direction == "direction":
                        count = 0
                        for d_2 in d_noise:
                            if d1[e][x] == d_2[e][x]:
                                count += 1
                        if (count / len(d_noise)) < 0.95:
                            file.write("\\cellcolor{Bittersweet}" + str(d1[e][x]) + "&" + "\\cellcolor{Bittersweet}" + str(
                                round(100 * (count / len(d_noise)), 0)))
                        else:
                            file.write(str(d1[e][x]) + "&" + str(round(100 * (count / len(d_noise)), 0)))
                    else:
                        count = 0
                        for d_2 in d_noise:
                            if type(d_2[e][x]) == float and d_2[e][x] != "N/A":
                                #print(d_2[e][x])
                                count += d_2[e][x]
                            else:
                                count += 0.5
                        if abs(d1[e][x] - count/len(d_noise)) > 0.01:
                            file.write("\\cellcolor{Bittersweet}" + str(d1[e][x]) + "&" + "\\cellcolor{Bittersweet}" + str(
                                round((count / len(d_noise)), 0)))
                        else:
                            file.write(str(d1[e][x]) + "&" + str(round((count / len(d_noise)), 0)))
                else:
                    if d1[e][x] == d2[e][x]:
                        file.write(str(d1[e][x]) + "&" + str(d2[e][x]))
                    else:
                        file.write("\\cellcolor{Bittersweet}" + str(d1[e][x]) + "&" + "\\cellcolor{Bittersweet}" + str(d2[e][x]))
                if x != "flees_startled":
                    file.write("&")
            file.write("\\\\")
        file.write("\\bottomrule")
        file.write("\\end{tabular}")
        file.write("\\caption{Evidence set with effect on hypothesis nodes." + str(params) + " " + str(direction) + "}")
        file.write("\\end{table}")




def experiment_with_normal_noise():
    for params in [[0, 0.001, "Normal (M, sd)"], [0, 0.01, "Normal (M, sd)"], [0, 0.1, "Normal (M, sd)"],
                   [0, 0.2, "Normal (M, sd)"], [0, 0.3, "Normal (M, sd)"], [0, 0.5, "Normal (M, sd)"]]:
        d_noise_list = []
        d4_noise_list = []
        smallest_change = 1
        largest_change = 0
        for i in range(0, 200):
            [BN_file_name, l, s] = disturb_cpts(experiment, "normalNoise", params)
            if abs(l) > largest_change:
                largest_change = l
            if abs(s) < smallest_change:
                smallest_change = s
            d_1 = determine_posterior_direction_or_precision("BayesNets/K2BN.net", "direction")
            d_2 = determine_posterior_direction_or_precision(f"NoiseBN{params[1]}.net", "direction")
            d_noise_list.append(d_2)

            d_3 = determine_posterior_direction_or_precision("BayesNets/K2BN.net", "precision")
            d_4 = determine_posterior_direction_or_precision(f"NoiseBN{params[1]}.net", "precision")
            d4_noise_list.append(d_4)

        print(params, largest_change, smallest_change)
        comp_count(d_1, d_noise_list, f'texTables/diffOutcomesDIR{params[1]}.tex', params, "direction")
        comp_count(d_3, d4_noise_list, f'texTables/diffOutcomesPRE{params[1]}.tex', params, "precision")

        get_hypothesis_posteriors_in_table(experiment, "BayesNets/K2BN.net", d_1, d_noise_list, f'texTables/diffOutcomesDIRNOISEHYPS{params[1]}.tex', params, "noise", "direction")
        get_hypothesis_posteriors_in_table(experiment, "BayesNets/K2BN.net", d_3, d4_noise_list, f'texTables/diffOutcomesPRENOISEHYPS{params[1]}.tex', params, "noise", "precision")

        # comp(d_1, d_2, f'texTables/diffOutcomes{params[1]}.tex', params)
        print("generated 2x table for ", params)


def experiment_general_shape(type_exp, param_list, general_latex_file):
    d_2 = []
    noise = "no noise"
    relevant_files = []
    for params in param_list:
        [disturbed_BN_file_name, empty] = disturb_cpts(experiment, type_exp, params)
        for x in ["direction", "precision"]:
            d_1 = determine_posterior_direction_or_precision("BayesNets/K2BN.net", x)
            if type_exp == "normalNoise":
                for i in range(0, 200):
                    noise = "noise"
                    d_i = determine_posterior_direction_or_precision(disturbed_BN_file_name, x)
                    d_2.append(d_i)
            else:
                [disturbed_BN_file_name, empty] = disturb_cpts(experiment, type_exp, params)
                d_2 = determine_posterior_direction_or_precision(disturbed_BN_file_name, x)
            comp_count(d_1, d_2, f'texTables/new/{x}{disturbed_BN_file_name}.tex', params, x)
            get_hypothesis_posteriors_in_table(experiment, "BayesNets/K2BN.net", d_1, d_2, f'texTables/new/hyp{x}{disturbed_BN_file_name}.tex', params, noise, x)
            relevant_files.append(f'texTables/new/{x}{disturbed_BN_file_name}.tex')
            relevant_files.append(f'texTables/new/hyp{x}{disturbed_BN_file_name}.tex')
    # output of experiment
    with open(general_latex_file, 'w') as file:
        for f in relevant_files:
            file.write("\\input{../simulationTest/" + f + "}\n")


experiment = Experiment()
K2_BN(experiment, "globalStates.csv", "BayesNets/K2BN.net")

param_no = [[0, 0.001, "Normal (M, sd)"], [0, 0.01, "Normal (M, sd)"], [0, 0.1, "Normal (M, sd)"],
                   [0, 0.2, "Normal (M, sd)"], [0, 0.3, "Normal (M, sd)"], [0, 0.5, "Normal (M, sd)"]]

param_ro = [[5, 'decimal places'], [4, 'decimal places'], [3, 'decimal places'],
                   [2, 'decimal places'], [1, 'decimal places'], [0, 'decimal places']]

param_ar = [[0.05, 'arbit'], [0.1, 'arbit'], [0.125, 'arbit'],
                   [0.2, 'arbit'], [0.25, 'arbit'],[0.33, 'arbit'],
                   [0.5, 'arbit']]

gen_file = '_collected_tables.tex'
for (exp, params) in [("rounded", param_ro), ("arbitraryRounded", param_ar)]: #, ("normalNoise", param_no)]:
    experiment_general_shape(exp, params, f"{exp}{gen_file}")
    print(f"done with experiment {exp}")


#experiment_with_normal_noise()
#experiment_with_rounding()
#experiment_with_arbitrary_rounding()