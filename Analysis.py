import pyAgrum as gum
import copy as copy
from Experiment import Experiment
from BN import K2_BN
import csv
import pandas as pd
import math
import numpy as np
from collections import defaultdict
import csv
import os
from CredibilityGame import CredibilityGame


def disturb_cpts(experiment, disturb_type, params_list, file_name):
    if ".net" not in file_name:
        file_name_load = file_name + ".net"
    #file_name = "K2BN.net"
    #K2_BN(experiment, "globalStates.csv", file_name)

    #print(file_name)

    org = os.getcwd()
    if experiment.bnDir not in org:
        os.chdir(experiment.bnDir)
    bn1 = gum.loadBN(file_name_load)
    bn = gum.BayesNet(bn1)
    noise_list = []


    if disturb_type == "normalNoise":
        '''
        The probabilities in the cpt are not the probabilities generated by K2,
        but they're distorted by a noise error (e)
            X'(X=1) = X(X=1) - e
            X'(X=0) = X(X=0) + e    (or vice versa)

        where e is drawn from a truncatec normal distribution with 
        M = 0, SD = 0.2 (tune parameters later) - the distribution cannot be o . For
        every variable we draw again from this normal distribution.

        This might represent the best case scenario for human estimations
        of probability - even if we cannot know the exact probability,
        we might be able to estimate them closely enough.

        However, it is very likely that our probability estimations
        do not work according to this standard-noise model. For instance,
        racial (or other societal) biases cannot be assumed to 
        be modelled with a "normal" divergence (the noise will be
        predisposed to go into "one direction", and not the other).

        However, first we need to see if BNs are robust against this 
        most simple noise-type of error.

        '''
        m, sd, type = params_list
        smallest_change = 1
        largest_change = 0
        nodes = bn.nodes()  # list of nodes to iterate over (names don't matter because noise is all the same
        for node in list(nodes):
            x = bn.cpt(node)
            name = x.var_names[-1]
            e = np.random.normal(loc=m, scale=sd)
            noise_list.append(e)
            # print(name, e)
            for i in bn.cpt(name).loopIn():
                if i.todict()[name] == 0:
                    bn.cpt(name).set(i, keep_in_range(bn.cpt(name).get(i) + e))
                elif i.todict()[name] == 1:
                    bn.cpt(name).set(i, keep_in_range(bn.cpt(name).get(i) - e))
            if abs(e) > largest_change:
                largest_change = abs(e)
            if abs(e) < smallest_change:
                smallest_change = abs(e)
        # print(largest_change, smallest_change)

        final_file_name = f"{file_name}{disturb_type}BN{str(sd)}"
        gum.saveBN(bn, f"{final_file_name}.net")
        # print(f"saved bn as {file_name}")
        os.chdir(org)
        return [final_file_name, [largest_change, smallest_change]]

    if disturb_type == "rounded":
        ''' we want to round the BN
        to some degree of decimals,
        since humans are not really accurate at 0.0001
        estimations.
        So then we want to get to 0.1, or 0.01 level rounding  (params_list)
        in the network, to see what happens then.
        '''
        [decimal_place, rounded_name] = params_list
        nodes = bn.nodes()  # list of nodes to iterate over (names don't matter because noise is all the same
        for node in list(nodes):
            x = bn.cpt(node)
            name = x.var_names[-1]
            for i in bn.cpt(name).loopIn():
                bn.cpt(name).set(i, round(bn.cpt(name).get(i), decimal_place))

        final_file_name = f"{file_name}{disturb_type}BN{str(decimal_place)}"
        #print("four", final_file_name)
        gum.saveBN(bn, f"{final_file_name}.net")
        os.chdir(org)
        return [final_file_name, "empty"]

    if disturb_type == "arbitraryRounded":
        ''' we want to round the BN
        to some degree (round to quartile, octile, thirds, 2nds, hwatever,
        since we like round numbers

        '''
        [step, rounded_name] = params_list
        nodes = bn.nodes()  # list of nodes to iterate over (names don't matter because noise is all the same
        for node in list(nodes):
            x = bn.cpt(node)
            name = x.var_names[-1]
            for i in bn.cpt(name).loopIn():
                val = bn.cpt(name).get(i)
                val = val
                y = math.floor((val / step) + 0.5) * step
                bn.cpt(name).set(i, y)

        final_file_name = f"{file_name}{disturb_type}BN{step}"
        gum.saveBN(bn, f"{final_file_name}.net")
        os.chdir(org)

        return [final_file_name, "empty"]


def determine_winning_hypothesis(false_val, true_val):
    x = ""
    if false_val > true_val:
        x = "H0"
    elif false_val < true_val:
        x = "H1"
    else:
        x = "0"
    return x

def find_posterior_based_on_evidence():
    pass

def get_evidence_list():
    '''
    evidence needs to be added in the correct order
     this is determined by the investigator,
     and the order is determined in this function.
     '''
    evidence_order = []
    if experiment.scenario == "StolenLaptop":
        evidence_order = ["E_object_is_gone", "E_broken_lock", "E_disturbed_house", "E_s_spotted_by_house", "E_s_spotted_with_goodie", "E_private"]
    elif experiment.scenario == "CredibilityGame":
        for i in range(0, experiment.n):
            str1 = f"E_{i}_says_stolen"
            # str2 = i + "_credibility"
            evidence_order.append(str1)
    return evidence_order


def determine_posterior_direction_or_precision(dir, file_name, direction):  # type is 'direction' or 'precision
    #if file_name != "BayesNets/K2BN.net":
    #    bn = gum.loadBN(f"{file_name}.net")
    #else:



    if "net" not in file_name:
        file_name = file_name + ".net"

    org_dir = os.getcwd()
    #print(org_dir)


    if dir not in os.getcwd():
        os.chdir(dir)

    bn = gum.loadBN(file_name)
    os.chdir(org_dir)

    direction_dict = {}
    ie = gum.LazyPropagation(bn)
    event_list = list(bn.names())#experiment.reporters.relevant_events
    e_dict = {}
    for node in list(bn.names()):
        x = bn.cpt(node)
        name = x.var_names[-1]
        if name[0] != 'E':  # we do not care about evidence nodes
            if direction == "weak":
                e_dict[name] = determine_winning_hypothesis(ie.posterior(node)[0], ie.posterior(node)[1]) # compare the posteriors (false, true) for node "name"
            elif direction == "strong":  # we just want to know the posterior for truth of a node
                e_dict[name] = round(ie.posterior(node)[1], 2)
                #print(name, e_dict[name])

    direction_dict[("no_evidence", 0)] = e_dict

    evidence_list = get_evidence_list()

    for evidence in evidence_list:
        e_dict = {}
        if evidence != "E_private":
            val = 1
        else:
            val = 0
        ie.addEvidence(evidence, val)
        #print(evidence, val)

        for node in list(bn.nodes()):
            x = bn.cpt(node)
            name = x.var_names[-1]
            if name[0] != 'E':  # we do not care about evidence nodes
                try:
                    if direction == "weak":
                        e_dict[name] = determine_winning_hypothesis(ie.posterior(node)[0], ie.posterior(node)[1])
                    else:
                        e_dict[name] = round(ie.posterior(node)[1], 2)
                        #print("\t", name, e_dict[name])

                except:
                    e_dict[name] = "NA"


        direction_dict[(evidence, val)] = e_dict

    return direction_dict

def keep_in_range(x):
    ''' numbers in a ctp cannot be > 1 or < 0'''
    if x > 1:
        return 1
    if x < 0:
        return 0
    return x

def make_table_headings_based_on_events(relevant_events):
    str_tabular_formatting = "\\begin{tabular}{l"
    for i in range(0, len(relevant_events)):
        str_tabular_formatting = str_tabular_formatting + "|cc"
    str_tabular_formatting = str_tabular_formatting + "}"

    str_head = "\\multirow{2}{*}{Evidence} "
    for e in relevant_events:
        l_key = e.replace("_", " ")
        str_head = str_head + "& \\multicolumn{2}{c}{" + l_key + "}"
    str_head = str_head + "\\\\"

    for e in relevant_events:
        str_head = str_head + "& {K2} & {Dev}"
    str_head = str_head + "\\\\"
    return str_tabular_formatting, str_head



def get_outcomes_in_table(d1, d_noise, latex_file_name, params, direction, noise, relevant_events):  # compare two direction dictionaries
    tab_f, head_f = make_table_headings_based_on_events(relevant_events)
    if len(relevant_events) > 3:
        outcomes = "outcomes"
    else:
        outcomes = "hypotheses"

    with open(latex_file_name, 'w') as file:
        file.write("\\begin{table}")
        file.write(tab_f)
        file.write("\\toprule")
        file.write(head_f)
        file.write("\\midrule\n")

        for e in d1.keys():
            l_key = e[0].replace("_", " ")
            file.write(str(l_key) + ", " + str(e[1]) + " & ")
            for x in relevant_events:
                if direction == "weak":
                    if not noise:   # if not noise
                        d2 = d_noise

                        if d1[e][x] == d2[e][x]:
                            file.write(str(d1[e][x]) + "&" + str(d2[e][x]))
                        else:
                            file.write(
                                "\\cellcolor{Bittersweet}" + str(d1[e][x]) + "&" + "\\cellcolor{Bittersweet}" + str(
                                    d2[e][x]))
                    else:   #if noise
                        count = 0
                        for d2 in d_noise:
                            if d1[e][x] == d2[e][x]:
                                count += 1
                        if (count / len(d_noise)) < 0.95:
                            file.write("\\cellcolor{Bittersweet}" + str(d1[e][x]) + "&" + "\\cellcolor{Bittersweet}" + str(
                                round(100 * (count / len(d_noise)), 0)))
                        else:
                            file.write(str(d1[e][x]) + "&" + str(round(100 * (count / len(d_noise)), 0)))
                if direction == "strong":
                    if not noise:   # something number of nodes
                        d2 = d_noise
                        if type(d2[e][x]) == float and abs(d1[e][x] - d2[e][x]) < 0.05:
                            file.write(str(d1[e][x]) + "&" + str(d2[e][x]))
                        else:
                            file.write(
                                "\\cellcolor{Bittersweet}" + str(d1[e][x]) + "&" + "\\cellcolor{Bittersweet}" + str(
                                    d2[e][x]))
                    else: # noise randomness precisison
                        count = 0
                        for d2 in d_noise:
                            if type(d2[e][x]) == float and d2[e][x] != "NA":
                                count += d2[e][x]
                            else:
                                count += 0.5
                        if abs(d1[e][x] - (count / len(d_noise))) > 0.05:
                            file.write("\\cellcolor{Bittersweet}" + str(d1[e][x]) + "&" + "\\cellcolor{Bittersweet}" + str(
                                round((count / len(d_noise)), 0)))
                        else:
                            t = round((count / len(d_noise)), 0)
                            file.write(str(d1[e][x]) + "&" + str(t))

                if x != relevant_events[-1]:
                    file.write("&")
            file.write("\\\\")

        file.write("\\bottomrule")
        file.write("\\end{tabular}")
        file.write("\\caption{Effect of disturbance of " + str(params) + " on " + str(direction) + " view of " + str(outcomes) + ".}")
        file.write("\\end{table}")

def get_relevant_hyp_events(bnDir, org_BN, outcome_nodes):


    if ".net" not in org_BN:
        org_BN =  org_BN + ".net"
    os.chdir(bnDir)
    bn = gum.loadBN(org_BN)
    hyp_nodes = []
    for x in bn.names():
        if x not in outcome_nodes and x[0] != 'E':
            hyp_nodes.append(x)

    return hyp_nodes



def experiment_general_shape(main_exp, type_exp, org_BN, param_list, general_latex_file, experiment_list):

    # reset dir
    org_dir = os.getcwd()

    d_2 = []
    noise = False
    relevant_files = []
    if main_exp.scenario == "StolenLaptop":
        relevant_nodes_out = ["successful_stolen", "lost_object"]
        relevant_nodes_hyp = get_relevant_hyp_events(main_exp.bnDir, org_BN, relevant_nodes_out) #["curtains", "raining", "know_object", "target_object", "motive", "compromise_house", "flees_startled"]
    elif main_exp.scenario == "CredibilityGame":
        relevant_nodes_out = ["agent_steals"]
        relevant_nodes_hyp = get_relevant_hyp_events(main_exp.bnDir, org_BN, relevant_nodes_out) # no hyps here
    elif main_exp.scenario == "GroteMarkt":
        relevant_nodes_out = ["stealing_1_0", "stealing_2_0"]
        #relevant_nodes_hyp = get_relevant_hyp_events(main_exp.bnDir, org_BN, relevant_nodes_out)  # no hyps here
    # establish original BN
    for direc in ["weak", "strong"]:
        d_1 = determine_posterior_direction_or_precision(main_exp.bnDir, org_BN, direc)
        for a in d_1.keys():
            for b in d_1[a].keys():
                experiment_list.append(["K2", 0, direc, 0, a[0] + str(a[1]), b, d_1[a][b], d_1[a][b]])

    for params in param_list:
        [disturbed_BN_file_name, empty] = disturb_cpts(experiment, type_exp, params, org_BN)
        for direc in ["weak", "strong"]:
            if type_exp == "normalNoise":
                for i in range(0, 200):
                    noise = True
                    d_i = determine_posterior_direction_or_precision(main_exp.bnDir, disturbed_BN_file_name, direc)
                    d_2.append(d_i)

                    for a in d_i.keys():
                        for b in d_i[a].keys():
                            experiment_list.append([type_exp, params[1], direc, i, a[0]+str(a[1]), b, d_i[a][b], d_1[a][b]])

            else:
                [disturbed_BN_file_name, empty] = disturb_cpts(experiment, type_exp, params, org_BN)
                #print(disturbed_BN_file_name)
                d_2 = determine_posterior_direction_or_precision(main_exp.bnDir, disturbed_BN_file_name, direc)
                for a in d_2.keys():
                    for b in d_2[a].keys():
                        experiment_list.append([type_exp, params[0], direc, 0, a[0]+str(a[1]), b, d_2[a][b], d_1[a][b]])

            os.chdir(org_dir)
            outcome_table = f'texTables/outcome/{direc}{disturbed_BN_file_name}.tex'
            hyp_table = f'texTables/hyps/{direc}{disturbed_BN_file_name}.tex'


            #get_outcomes_in_table(d_1, d_2, outcome_table, params, direc, noise, relevant_nodes_out)
            #get_outcomes_in_table(d_1, d_2, hyp_table, params, direc, noise, relevant_nodes_hyp)


            relevant_files.append(outcome_table)
            relevant_files.append(hyp_table)

    # output of experiment
    with open(general_latex_file, 'w') as file:
        for f in relevant_files:
            file.write("\\input{../simulationTest/" + f + "}\n")





### intentions
scenario = "CredibilityGame"
#scenario = "GroteMarkt"

train_test_split = [2000, 200]

runs = train_test_split[0]

if scenario == "CredibilityGame":

    for game in ["basicGame", "strangeGame"]:

        experiment = Experiment(scenario="CredibilityGame", runs=runs, subtype=game)
        bnDir = experiment.bnDir
        dataFileName = experiment.csv_file_name



        K2_BN(experiment, dataFileName, "CredBNs/main.net")
        param_ar = [[0.05, 'arbit'], [0.1, 'arbit'], [0.125, 'arbit'],
                    [0.2, 'arbit'], [0.25, 'arbit'], [0.33, 'arbit'],
                    [0.5, 'arbit']]

        gen_file = f'_{game}_collected_tables.tex'
        experiment_list = []
        org_BN = "main"
        for (exp, params) in [("arbitraryRounded", param_ar)]:
            experiment_general_shape(experiment, exp, org_BN, params, f"texTables/{org_BN}{exp}{gen_file}", experiment_list)
            print(f"done with experiment {exp}")

        csv_cols = ["distortion", "param", "strong", "noise", "evidenceCUMUL", "hypNode", "Probability", "K2Probability", "Game"]
        flag = 'w'
        if game != "basicGame":
            flag = 'a'
        with open("cred.csv", flag) as file:
            writer = csv.writer(file)
            writer.writerow(csv_cols)
            for row in experiment_list:
                row.append(game)
                writer.writerow(row)

elif scenario == "GroteMarkt":
    experiment = Experiment(scenario="GroteMarkt", runs=runs, subtype=2)  # we do the simple scenario
    bnDir = experiment.bnDir
    dataFileName = experiment.csv_file_name

    K2_BN(experiment, dataFileName, "BNGroteMarkt/main.net")
    param_ar = [[0.05, 'arbit'], [0.1, 'arbit'], [0.125, 'arbit'],
                [0.2, 'arbit'], [0.25, 'arbit'], [0.33, 'arbit'],
                [0.5, 'arbit']]

    gen_file = f'_{scenario}_collected_tables.tex'
    experiment_list = []
    org_BN = "main"
    for (exp, params) in [("arbitraryRounded", param_ar)]:
        experiment_general_shape(experiment, exp, org_BN, params, f"texTables/{org_BN}{exp}{gen_file}", experiment_list)
        print(f"done with experiment {exp}")

    csv_cols = ["distortion", "param", "strong", "noise", "evidenceCUMUL", "hypNode", "Probability", "K2Probability",
                "Scenario"]
    flag = 'w'
    if experiment.subtype != "1":
        flag = 'a'
    with open("gm.csv", flag) as file:
        writer = csv.writer(file)
        writer.writerow(csv_cols)
        for row in experiment_list:
            writer.writerow(row)



elif scenario == "StolenLaptop":
    experiment = Experiment(scenario="StolenLaptop", runs=runs)
    bnDir = experiment.bnDir
    dataFileName = experiment.csv_file_name

    K2_BN(experiment, dataFileName, "K2Bns/K2BN.net")

    param_no = [[0, 0.001, "Normal (M, sd)"], [0, 0.01, "Normal (M, sd)"], [0, 0.1, "Normal (M, sd)"],
                       [0, 0.2, "Normal (M, sd)"], [0, 0.3, "Normal (M, sd)"], [0, 0.5, "Normal (M, sd)"]]

    param_ro = [[5, 'decimal places'], [4, 'decimal places'], [3, 'decimal places'],
                       [2, 'decimal places'], [1, 'decimal places'], [0, 'decimal places']]

    param_ar = [[0.05, 'arbit'], [0.1, 'arbit'], [0.125, 'arbit'],
                       [0.2, 'arbit'], [0.25, 'arbit'],[0.33, 'arbit'],
                       [0.5, 'arbit']]


    gen_file = '_collected_tables.tex'
    experiment_list = []
    org_BN = "K2BN"
    for (exp, params) in [("rounded", param_ro), ("arbitraryRounded", param_ar), ("normalNoise", param_no)]:
        experiment_general_shape(experiment, exp, org_BN, params, f"texTables/{org_BN}{exp}{gen_file}", experiment_list)
        print(f"done with experiment {exp}")

    csv_cols = ["distortion", "param", "strong", "noise", "evidenceCUMUL", "hypNode", "Probability", "K2Probability"]
    with open("expORG.csv", 'w') as file:
        writer = csv.writer(file)
        writer.writerow(csv_cols)
        writer.writerows(experiment_list)



    #### testing spider BN for hypothesis ####
    gen_file = '_collected_tables_spider.tex'
    org_BN = "adaptedK2BN"
    experiment_list_spider = []
    for (exp, params) in [("arbitraryRounded", param_ar)]:
        experiment_general_shape(experiment, exp, org_BN, params, f"texTables/{org_BN}{exp}{gen_file}", experiment_list_spider)
        print(f"done with experiment {exp}")

    csv_cols = ["distortion", "param", "strong", "noise", "evidenceCUMUL", "hypNode", "Probability", "K2Probability"]
    with open("expSpider.csv", 'w') as file:
        writer = csv.writer(file)
        writer.writerow(csv_cols)
        writer.writerows(experiment_list_spider)